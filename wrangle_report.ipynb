{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report explained the wrangled effort in analyzing and visualizing the tweet archieved of the WeRateDogs. The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. The wrangling process is divided into three stages:\n",
    "\n",
    "<ul>\n",
    "    <li>Gathering: The data used for this project was gathered from three different sources. The data and their sources are;\n",
    "        <ol>\n",
    "            <li>twitter_achieved_enhanced.csv: This file was given by the udacity team and I downloaded it manually using this link https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv, I then read and upload the data as twitter_data to pandas DataFrame. The file contains the tweet_id, names, ratings, retweet status, dog types etc.</li>\n",
    "            <li>image_prediction.tsv: The file is present in each tweet according to a neural network. It is hosted on Udacity's servers and I downloaded it programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv, I then read it into Pandas DataFrame as image_prediction.\n",
    "            </li>\n",
    "            <li>tweet_json.txt: I was unable to create a twitter developer account so i make use of the tweet json file provided by udacity, Then I read this tweet_json.txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count as tweet_data.</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Assessing: After gathering all three pieces of data, I assessed them visually and programmatically for quality and tidiness issues. Each piece of gathered data was displayed in the Jupyter Notebook for visual assessment. Microsoft excel was also used in accessing the gathered data visually. Pandas functions were also used in assessing the datas programmatically. The following are the quality and tidiness issues detected in the data;\n",
    "        \n",
    "### Quality issues\n",
    "        \n",
    "#### twitter_data table\n",
    "        \n",
    "1. tweet_id is not string\n",
    "\n",
    "2. timestamp is not datetime\n",
    "\n",
    "3. invalid dog names such as just, all, none, a, the, this, very, such, an, by, his, my, not\n",
    "\n",
    "4. zero denominator in row 313\n",
    "\n",
    "5. missing data in in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp\n",
    "\n",
    "#### image_prediction\n",
    "6. missing photos for some tweet IDs\n",
    "\n",
    "7. some names start with capital letters while others with small letters\n",
    "\n",
    "#### tweet_data\n",
    "8. missing data in id, retweet_count, favorite_count\n",
    "        \n",
    "### Tidiness issues\n",
    "1. id column instead on tweet_id in tweet_table\n",
    "\n",
    "2. dog types separated in different columnns\n",
    "    </li>\n",
    "    \n",
    "<li>Cleaning: The detected quality and tidiness issues were cleaned accordingly to enhance the quality of the data for analyzing and visualization.\n",
    "    </li>\n",
    "\n",
    "\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
